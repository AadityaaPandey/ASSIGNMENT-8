# ğŸš• NYC Yellow Taxi Data Analysis using PySpark (Databricks)

This project demonstrates analysis of NYC Yellow Taxi trip data using **Apache Spark (PySpark)** in **Databricks**. The dataset is ingested in **Parquet** format and analyzed to extract insights about passenger counts, earnings, locations, and revenue.

---

## ğŸ“ Dataset Used

The dataset is a sample of **NYC Yellow Taxi trips** (`yellow_tripdata_2018-01.parquet`), which includes pickup/drop-off times, locations, payment types, fare details, and more.

---

## ğŸ§ª Project Objectives

This notebook performs the following analytical tasks using **Spark SQL and DataFrames**:

1. **Load and Inspect Dataset**  
   ğŸ“Œ Loaded from a parquet file using `spark.read.format("parquet")`.

2. **Add Revenue Column**  
   ğŸ’° Revenue = fare + tip + tolls + surcharges + taxes

3. **Passenger Count by Pickup Location**  
   ğŸ” Aggregated total passengers by `PULocationID`.

4. **Average Fare & Earnings per Vendor**  
   ğŸ“Š Used `avg()` to compute average fare and earnings by `VendorID`.

5. **Moving Count by Payment Type Over Time**  
   ğŸ” Used `Window` function to create a running count for each payment type.

6. **Top Vendor Analysis (Earnings, Distance, Passenger Count)**  
   ğŸ“ˆ On a specific date (`2018-01-15`), determined top vendors by earnings.

7. **Most Frequent PU-DO Pair (Pickup-Dropoff)**  
   ğŸ“ Found the top route with the highest number of passengers.

8. **Last 10 Seconds of Data Analysis**  
   â±ï¸ Extracted records from the latest 10 seconds of available data.

---

## ğŸ“¸ Output Snapshots

> Screenshots of important analysis steps and results:

- âœ… Parquet File Load  
  ![Uploaded Parquet File](./Uploaded_parquet_file.png)

- âœ… Revenue Column Addition  
  ![Added Revenue Column](./Added_revenue_column.png)

- âœ… Passenger Counts by PU Location  
  ![PU Passenger Counts](./increasing_count_tot_passengers.png)

- âœ… Average Fare and Earnings  
  ![Average Earnings](./total_earnings.png)

- âœ… Moving Count by Payment Type  
  ![Moving Count](./moving_counts_payments.png)

- âœ… Most Frequent Route (PU-DO Pair)  
  ![Query 9](./Query_9.png) <!-- Add if screenshot exists -->

- âœ… Top Vendors by Earnings  
  ![Top Vendors](./Query_5.png)

- âœ… Data from Last 10 Seconds  
  ![Last 10 Seconds Analysis](./Query_7.png)

---

## ğŸ“¦ Technologies Used

| Tool/Language | Purpose |
|---------------|---------|
| **Apache Spark (PySpark)** | Big data processing |
| **Databricks** | Development and execution |
| **Parquet** | Efficient data format |
| **Python** | Programming language |

---

## ğŸ“ How to Run

1. Upload the parquet dataset to Databricks `/FileStore/tables/`
2. Import the notebook or run code snippets in a new Databricks notebook.
3. Make sure the **cluster is running** with a Spark-enabled runtime.
4. Adjust file paths and field names as per your data schema.

---

## ğŸ§  Insights Drawn

- Vendor 2 had the highest earnings on 2018-01-15.
- Most passengers originated from location ID 13.
- Pickup and drop at location 264 saw the maximum passenger count for a route.
- Vendor 2 provided slightly better average fare than Vendor 1.
- Significant variation exists in payment type usage over time.

---
#Assignment 8
- Aditya Kumar Pandey
